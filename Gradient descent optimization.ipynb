{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d848f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipywidgets --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6203d175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as la\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, IntSlider, FloatSlider, fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5c3469e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x, V, dV, num_dolphins, param, \n",
    "                     delta=1e-20, epsilon=1e-20, verbose=False):\n",
    "    x_old=np.zeros(len(x))\n",
    "    dV_old=np.zeros(len(x))\n",
    "    dV_current = dV(x, num_dolphins, param)\n",
    "    ddV = dV_current - dV_old\n",
    "    dx = x - x_old\n",
    "    F_norm = np.inner(ddV,ddV)\n",
    "    x_norm = la.norm(dx)\n",
    "    \n",
    "    step_count=0\n",
    "    loss_val = [[step_count],[V(x, num_dolphins, param)]]\n",
    "    \n",
    "    while x_norm > delta and F_norm > epsilon*epsilon:\n",
    "        gamma = np.abs(np.inner(dx,ddV))/F_norm\n",
    "        x_old = np.array(x)\n",
    "        dV_old = np.array(dV_current)\n",
    "        x = x - gamma*dV_current\n",
    "        \n",
    "        dV_current=dV(x, num_dolphins, param)\n",
    "        \n",
    "        ddV = dV_current - dV_old\n",
    "        dx = x - x_old\n",
    "        F_norm = np.inner(ddV,ddV)\n",
    "        x_norm = la.norm(dx)\n",
    "        step_count += 1\n",
    "        loss_val[0].append(step_count)\n",
    "        loss_val[1].append(V(x, num_dolphins, param))\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Epoch: {step_count} - Cost: {V(x, num_dolphins, param)}...\")\n",
    "            print(\"---------------------------------------\")\n",
    "    \n",
    "    print(\"\\n\\n\")\n",
    "    if verbose:\n",
    "        print(f\"Descent converges at {x.reshape((num_dolphins, 3))[0, :]}\")\n",
    "        for i in range(1, num_dolphins):\n",
    "            print(f\"                      {x.reshape((num_dolphins, 3))[i, :]}\")\n",
    "        \n",
    "    return x, loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "404864b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cost_function(r, num_dolphins, param):\n",
    "    \n",
    "    if not isinstance(r, np.ndarray):\n",
    "        r = np.array(r)\n",
    "        \n",
    "    r = r.reshape((num_dolphins, 3))    \n",
    "    \n",
    "    cost = 0\n",
    "    for i in range(0, num_dolphins):\n",
    "        for j in range(i, num_dolphins):\n",
    "            if i==j:\n",
    "                continue\n",
    "            else:\n",
    "                r_ij = ((r[j, 0]-r[i, 0])**2) + ((r[j, 1]-r[i, 1])**2) + ((r[j, 2]-r[i, 2])**2)\n",
    "                cost += r_ij + 1/r_ij  \n",
    "            \n",
    "    return cost\n",
    "\n",
    "\n",
    "def cost_der(r, num_dolphins, param):  # cost derivative\n",
    "    \n",
    "    r = r.reshape((num_dolphins, 3))\n",
    "    \n",
    "    derr_array = np.zeros((num_dolphins, 3))\n",
    "    \n",
    "    dvdx, dvdy, dvdz = 0, 0, 0\n",
    "    \n",
    "    for i in range(0, num_dolphins):\n",
    "        for j in range (i, num_dolphins):\n",
    "            if i==j:\n",
    "                continue\n",
    "            else:\n",
    "                r_ij = ((r[j, 0]-r[i, 0])**2) + ((r[j, 1]-r[i, 1])**2) + ((r[j, 2]-r[i, 2])**2)\n",
    "                dvdx += 2*(r[j, 0] - r[i, 0])*(1-r_ij**2)/(r_ij**2)\n",
    "                dvdy += 2*(r[j, 1] - r[i, 1])*(1-r_ij**2)/(r_ij**2)\n",
    "                dvdz += 2*(r[j, 2] - r[i, 2])*(1-r_ij**2)/(r_ij**2)\n",
    "        \n",
    "        derr_array[i, 0] = dvdx\n",
    "        derr_array[i, 1] = dvdy\n",
    "        derr_array[i, 2] = dvdz\n",
    "        \n",
    "        dvdx, dvdy, dvdz = 0, 0, 0\n",
    "          \n",
    "    \n",
    "    derr_array = derr_array.flatten()\n",
    "    \n",
    "    return derr_array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f617bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_pos_n_cost means get position and cost\n",
    "def get_pos_n_cost(num_dolphins:int=3, verbose=False):\n",
    "\n",
    "    param=[4.0,8.0,3.0,1.0]\n",
    "\n",
    "    x = np.random.randint(-10, 10, (num_dolphins, 3)).flatten()\n",
    "    x_init = x.reshape((num_dolphins, 3))\n",
    "    \n",
    "    x_final, loss_val = gradient_descent(x, cost_function, cost_der, num_dolphins, param, verbose=verbose)\n",
    "    x_final = x_final.reshape((num_dolphins, 3))\n",
    "\n",
    "    fig, axs = plt.subplots(figsize=(14,8))\n",
    "    font = {'family': 'serif', 'color': 'black', 'weight': 'bold', 'size': 16}\n",
    "\n",
    "    axs.plot(loss_val[0], loss_val[1], 'r-', label='Cost')\n",
    "    axs.set_xlabel('$Epoch$', fontdict=font, labelpad=10)\n",
    "    axs.set_ylabel('$Cost$ $(r)$', fontdict=font, labelpad=10)\n",
    "    axs.set_title(\"Cost as a function of Epochs\", fontdict=font)\n",
    "    axs.legend()\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    fig, axs = plt.subplots(figsize=(14,8))\n",
    "    font = {'family': 'serif', 'color': 'black', 'weight': 'bold', 'size': 16}\n",
    "    \n",
    "    axs = plt.axes(projection='3d')\n",
    "    \n",
    "    axs.set_xlim([min(x_final[:, 0].min(), x_init[:, 0].min())  - 0.25, \n",
    "                 max(x_final[:, 0].max(), x_init[:, 0].max())  + 0.25])\n",
    "    axs.set_ylim([min(x_final[:, 1].min(), x_init[:, 1].min()) - 0.25, \n",
    "                  max(x_final[:, 1].max(), x_init[:, 1].max()) + 0.25])\n",
    "    axs.set_zlim([min(x_final[:, 2].min(), x_init[:, 2].min()) - 0.25, \n",
    "                  max(x_final[:, 2].max(), x_init[:, 2].max()) + 0.25])\n",
    "    \n",
    "    axs.scatter(*x_final.T, marker='o', color='b', linewidths=4, label='Final Dolphin Positions')\n",
    "    axs.scatter(*x_init.T, marker='*', color='r', linewidths=4,  label='Initial Dolphin Positions')\n",
    "\n",
    "    axs.set_xlabel(r'x ($\\sigma$)', fontdict=font, labelpad=10)\n",
    "    axs.set_ylabel(r'y ($\\sigma$)', fontdict=font, labelpad=10)\n",
    "    axs.set_zlabel(r'z ($\\sigma$)', fontdict=font, labelpad=10)\n",
    "    axs.set_title(\"Inital and Final Dolphin Positions\", fontdict=font)\n",
    "    axs.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e64c368c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64590ec9fe664b89892938010d5fd4dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=3, description='num_dolphins', max=12, min=-3), Checkbox(value=False, de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.get_pos_n_cost(num_dolphins: int = 3, verbose=False)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of dolphins = 3\n",
    "interact(get_pos_n_cost, num_dolphins=widgets.IntSlider(min=-3.0, max=12.0, step=1, value=3), verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f26529b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b6af7074de54a01a147d2902b8e554f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=4, description='num_dolphins', max=12, min=-3), Checkbox(value=False, de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.get_pos_n_cost(num_dolphins: int = 3, verbose=False)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of dolphins = 4\n",
    "interact(get_pos_n_cost, num_dolphins=widgets.IntSlider(min=-3.0, max=12.0, step=1, value=4), verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c01440e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b395502fcf32428a8eede3766f861a61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=6, description='num_dolphins', max=12, min=-3), Checkbox(value=False, de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.get_pos_n_cost(num_dolphins: int = 3, verbose=False)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of dolphins = 6\n",
    "interact(get_pos_n_cost, num_dolphins=widgets.IntSlider(min=-3.0, max=12.0, step=1, value=6), verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0556abe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a31027bf7d434aa682305e822cf0a466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=8, description='num_dolphins', max=12, min=-3), Checkbox(value=False, de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.get_pos_n_cost(num_dolphins: int = 3, verbose=False)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of dolphins = 8\n",
    "interact(get_pos_n_cost, num_dolphins=widgets.IntSlider(min=-3.0, max=12.0, step=1, value=8), verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04069c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2be5d7e0539f407a98dfcb7a2f20cd2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=10, description='num_dolphins', max=12, min=-3), Checkbox(value=False, d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.get_pos_n_cost(num_dolphins: int = 3, verbose=False)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of dolphins = 10\n",
    "interact(get_pos_n_cost, num_dolphins=widgets.IntSlider(min=-3.0, max=12.0, step=1, value=10), verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459a5733",
   "metadata": {},
   "source": [
    "### Comments\n",
    "2b) Gradient descent optimization an optimization algorithm to find the minimum of a function. We start with a random point on the function and move in the negative direction of the gradient of the function to reach the local/global minima.\n",
    "Above, I provided an interactive widget so we can see that as we increase the number of dolphins, the minimum value of the cost will continue to increase which implies that the cost depends on the number of dolphins.\n",
    "\n",
    "The cost function is well defined, derivable, and convex since the second derivative of the cost function is greater than 0, the plot for the cost function versus the number of iterations is very steep. However, I do not think the configuration is the optimum result. It only shows that gamma(learning rate) is too high and the implication of this is that the cost function might be converging too quickly to a suboptimal solution. Gamma determines how large of a step should be taken on each iteration in the direction opposite of the gradient (again because we are trying to minimize the cost function). The method may skip over the actual optimal result if we have a larger step.\n",
    "\n",
    "The model can yield a more optimal solution if gamma is reduced i.e. a smaller learning rate. However, this will significantly increase time complexity by increasing the number of iterations it would take for the cost function to converge. Therefore, we can slowly change gamma until the cost function versus number of iterations curve is smooth exponential decay.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e875058",
   "metadata": {},
   "source": [
    "### DISCLAIMER \n",
    "#### I USED THE CODES PROVIDED IN THE GRADIENT DESCENT HANDOUT GIVEN IN CLASS BY DR. SAGAR PANDIT\n",
    "https://machinelearningmastery.com/tour-of-optimization-algorithms/\n",
    "https://towardsdatascience.com/implement-gradient-descent-in-python-9b93ed7108d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146b6860",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
